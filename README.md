# Gesture Volume Control ğŸ›ï¸âœ‹

This project allows you to control your system's volume using hand gestures, leveraging computer vision and machine learning techniques. The application uses a webcam to detect hand movements and adjusts the volume accordingly.

---

## Features ğŸš€
- **Hand Tracking**: Detects and tracks your hand in real-time using MediaPipe.
- **Gesture Recognition**: Measures the distance between your thumb and index finger to control the volume.
- **Real-Time Feedback**: Displays the current volume level and FPS on the screen.
- **Interactive UI**: Visualizes hand landmarks and gestures with dynamic graphics.

---

## Demo ğŸ¥
![Demo](./img/cover.png)

---

## Installation ğŸ› ï¸

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/Gesture-Volume-Control.git
   cd Gesture-Volume-Control
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run the application:
   ```bash
   python main.py
   ```

---

## Requirements ğŸ“‹
- Python 3.7+
- Webcam
- Libraries:
  - OpenCV
  - MediaPipe
  - NumPy
  - Pycaw
  - Comtypes

---

## How It Works ğŸ§ 
1. **Hand Detection**: The application uses MediaPipe to detect and track hand landmarks.
2. **Gesture Calculation**: The distance between the thumb and index finger is calculated to determine the desired volume level.
3. **Volume Adjustment**: The Pycaw library is used to adjust the system's master volume based on the gesture.

---

## Controls ğŸ®
- **Adjust Volume**: Move your thumb and index finger closer or farther apart.
- **Quit Application**: Press the `q` key.

---

## File Structure ğŸ“‚
```
Gesture-Volume-Control/
â”œâ”€â”€ HandTrackingModule.py   # Custom module for hand tracking
â”œâ”€â”€ main.py                 # Main application script
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ .gitignore              # Git ignore file
â”œâ”€â”€ img/                    # Folder containing images
â”‚   â””â”€â”€ cover.png           # Demo cover image
â””â”€â”€ README.md               # Project documentation
```

---

## Known Issues ğŸ
- The application may not work well in low-light conditions.
- Hand detection accuracy may vary depending on the webcam quality.

---

## Future Improvements ğŸŒŸ
- Add support for more gestures.
- Implement multi-hand tracking.
- Enhance UI with additional visual feedback.

---

## Contributing ğŸ¤
Contributions are welcome! Feel free to fork the repository and submit a pull request.

---

## License ğŸ“œ
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## Acknowledgments ğŸ™Œ
- [MediaPipe](https://mediapipe.dev/) for hand tracking.
- [Pycaw](https://github.com/AndreMiras/pycaw) for audio control.
- OpenCV and NumPy for image processing.

---

Enjoy controlling your volume with gestures! âœ‹ğŸ¶